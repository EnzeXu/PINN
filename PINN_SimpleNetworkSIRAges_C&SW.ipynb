{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2347,
     "status": "ok",
     "timestamp": 1657242552820,
     "user": {
      "displayName": "Group Chen",
      "userId": "07021887056990447026"
     },
     "user_tz": 240
    },
    "id": "B3Ti9-7_CWm2",
    "outputId": "f6fddf6b-a11e-48cc-94dd-fdb25a0503b0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Enze Xu\n",
    "# Github: https://github.com/EnzeXu/PINN\n",
    "# git clone https://github.com/EnzeXu/PINN.git\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from torchsummary import summary\n",
    "from torch.backends import cudnn\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.integrate import odeint\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from google.colab import drive\n",
    "import sys\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "main_path = '/content/drive/My Drive/enze/workspace/PINN/' # ENZE marked: you need to change your main_path if it's not here\n",
    "sys.path.append(main_path)\n",
    "from cyclic_lr_scheduler import CyclicLR\n",
    "from utils import draw_two_dimension, draw_two_dimension_different_x, draw_multiple_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3R1sJbXEGMQt"
   },
   "outputs": [],
   "source": [
    "# rmse = RMSELoss()\n",
    "# mse = nn.MSELoss()\n",
    "# zeros_1D = torch.Tensor([[0.0]] * 3)\n",
    "# a = torch.Tensor([[1], [2], [3]])\n",
    "# print(rmse(a, zeros_1D))\n",
    "# print(mse(a, zeros_1D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3642,
     "status": "ok",
     "timestamp": 1657242556459,
     "user": {
      "displayName": "Group Chen",
      "userId": "07021887056990447026"
     },
     "user_tz": 240
    },
    "id": "cYCehNpNCWm2"
   },
   "outputs": [],
   "source": [
    "class ConfigSIRAges:\n",
    "    def __init__(self):\n",
    "        self.model_name = \"SimpleNetworkSIRAges_Truth\"\n",
    "        self.T = 100.0\n",
    "        self.T_all = self.T\n",
    "        self.T_unit = 0.1\n",
    "        self.N = int(self.T / self.T_unit)\n",
    "        self.S_start = 50.0  # 99.0\n",
    "        self.I_start = 40.0 # 1.0\n",
    "        self.R_start = 10.0 # 0.0\n",
    "        self.NN = self.S_start + self.I_start + self.R_start\n",
    "        self.beta = 0.01  # 0.01\n",
    "        self.gamma = 0.05 # 0.05\n",
    "        self.ub = self.T\n",
    "        self.lb = 0.0\n",
    "        self.mu = 0.03\n",
    "        self.lam = self.mu * self.NN\n",
    "\n",
    "        self.M = np.asarray([\n",
    "          [19.200, 4.800, 5.050, 3.400, 1.700],\n",
    "          [4.800, 42.400, 5.900, 6.250, 1.733],\n",
    "          [5.050, 5.900, 14.000, 7.575, 1.700],\n",
    "          [3.400, 6.250, 7.575, 9.575, 1.544],\n",
    "          [1.700, 1.733, 1.700, 1.544, 5.456],\n",
    "        ])\n",
    "        self.n = len(self.M)\n",
    "\n",
    "        self.seed = 0\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.gt_real = GroundTruthSIRAges(self.T, self.N)\n",
    "        self.gt_real_data = torch.tensor(self.gt_real.data).to(self.device)\n",
    "        self.x_real = torch.tensor(np.asarray([[i*self.T_unit] * (self.n * 3) for i in range(self.N)]) / self.T_all * 2.0 - 1.0).float().to(self.device)\n",
    "        print(\"[continuous] self.x_real: shape = {}\".format(self.x_real.shape))\n",
    "\n",
    "        self.only_truth_flag = False\n",
    "        self.truth_rate = 0.001\n",
    "        self.truth_length = int(self.truth_rate * self.T / self.T_unit)\n",
    "\n",
    "        self.continuous_flag = False\n",
    "        self.continue_period = 0.2\n",
    "        self.round_bit = 3\n",
    "        self.continue_id = None\n",
    "        self.mapping_overall_flag = True\n",
    "\n",
    "        self.sliding_window_flag = False\n",
    "        self.sw_normal_flag=False\n",
    "        self.normal_sliding_window_step = 50000\n",
    "        self.sw_brick_flag=False\n",
    "        self.epoch_max=None\n",
    "        \n",
    "\n",
    "\n",
    "# class RMSELoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.mse = nn.MSELoss()\n",
    "#         self.eps = 1e-8\n",
    "        \n",
    "#     def forward(self, y_pred, y):\n",
    "#         return torch.sqrt(self.mse(y_pred, y) + self.eps)\n",
    "\n",
    "def RMSELoss(y_pred, y):\n",
    "    return torch.sqrt(torch.mean((y_pred - y)**2) + 1e-12)\n",
    "\n",
    "\n",
    "class SimpleNetworkSIRAges(nn.Module):\n",
    "    def __init__(self, config, truth=None):\n",
    "        super(SimpleNetworkSIRAges, self).__init__()\n",
    "        self.config = config\n",
    "        print(\"self.truth_length: {} of {} all \".format(self.config.truth_length, self.config.N))\n",
    "        self.setup_seed(self.config.seed)\n",
    "        self.device = self.config.device\n",
    "        self.x, self.y0, self.t0 = None, None, None\n",
    "        self.accurate_x = None\n",
    "        self.generate_x()\n",
    "        # self.optimizer = optim.LBFGS(self.parameters(), lr=0.001, max_iter=5000, max_eval=None, tolerance_grad=1e-05, tolerance_change=1e-09, history_size=100, line_search_fn=None)\n",
    "        self.initial_start()\n",
    "        self.model_name = self.config.model_name\n",
    "        self.gt = GroundTruthSIRAges(self.config.T, self.config.N)\n",
    "        self.gt_data = torch.Tensor(self.gt.data).to(self.device)\n",
    "        self.y_record = None\n",
    "        self.sig = nn.Tanh()\n",
    "\n",
    "        self.loss_norm = RMSELoss\n",
    "        self.truth = truth if truth else [[], []]\n",
    "        self.truth_dic = {round(self.truth[0][i], self.config.round_bit): self.truth[1][i] for i in range(len(self.truth[0]))}\n",
    "\n",
    "        self.network_unit = 20\n",
    "        # Design A\n",
    "        # id = 1\n",
    "        self.fc_x1_id1 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        self.fc_x2_id1 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        self.fc_x3_id1 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        # id = 2\n",
    "        self.fc_x1_id2 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        self.fc_x2_id2 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        self.fc_x3_id2 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        # id = 3\n",
    "        self.fc_x1_id3 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        self.fc_x2_id3 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        self.fc_x3_id3 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        # id = 4\n",
    "        self.fc_x1_id4 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        self.fc_x2_id4 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        self.fc_x3_id4 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        # id = 5\n",
    "        self.fc_x1_id5 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        self.fc_x2_id5 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        self.fc_x3_id5 = nn.Sequential(OrderedDict({\n",
    "            'lin1': nn.Linear(1, self.network_unit),\n",
    "            'sig1': self.sig,\n",
    "            'lin2': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig2': self.sig,\n",
    "            'lin3': nn.Linear(self.network_unit, self.network_unit),\n",
    "            'sig3': self.sig,\n",
    "            'lin4': nn.Linear(self.network_unit, 1),\n",
    "            # 'sig4': nn.ReLU()\n",
    "        }))\n",
    "\n",
    "        # # Design D\n",
    "        # # id = 1\n",
    "        # self.fc_x1_0_1_id1 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_0_1_id1 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_0_1_id1 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_1_2_id1 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_1_2_id1 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_1_2_id1 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1 * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_2_3_id1 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_2_3_id1 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_2_3_id1 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1 * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_3_4_id1 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_3_4_id1 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_3_4_id1 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # # id = 2\n",
    "        # self.fc_x1_0_1_id2 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_0_1_id2 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_0_1_id2 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_1_2_id2 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_1_2_id2 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_1_2_id2 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1 * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_2_3_id2 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_2_3_id2 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_2_3_id2 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1 * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_3_4_id2 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_3_4_id2 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_3_4_id2 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # # id = 3\n",
    "        # self.fc_x1_0_1_id3 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_0_1_id3 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_0_1_id3 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_1_2_id3 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_1_2_id3 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_1_2_id3 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1 * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_2_3_id3 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_2_3_id3 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_2_3_id3 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1 * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_3_4_id3 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_3_4_id3 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_3_4_id3 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # # id = 4\n",
    "        # self.fc_x1_0_1_id4 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_0_1_id4 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_0_1_id4 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_1_2_id4 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_1_2_id4 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_1_2_id4 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1 * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_2_3_id4 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_2_3_id4 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_2_3_id4 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1 * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_3_4_id4 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_3_4_id4 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_3_4_id4 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # # id = 5\n",
    "        # self.fc_x1_0_1_id5 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_0_1_id5 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_0_1_id5 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_1_2_id5 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_1_2_id5 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_1_2_id5 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1 * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_2_3_id5 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_2_3_id5 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear((self.config.n + 1) * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_2_3_id5 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(1 * self.network_unit, self.network_unit),\n",
    "        #     'sig1': self.sig,\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x1_3_4_id5 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x2_3_4_id5 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "        # self.fc_x3_3_4_id5 = nn.Sequential(OrderedDict({\n",
    "        #     'lin1': nn.Linear(self.network_unit, 1),\n",
    "        # }))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # print(inputs.shape)\n",
    "        # print(\"inputs=\", inputs)\n",
    "        x1_id1, x1_id2, x1_id3, x1_id4, x1_id5, x2_id1, x2_id2, x2_id3, x2_id4, x2_id5, x3_id1, x3_id2, x3_id3, x3_id4, x3_id5 = torch.chunk(inputs, 15, 1)\n",
    "        \n",
    "        # Design A\n",
    "        x1_new_id1 = self.fc_x1_id1(x1_id1)\n",
    "        x2_new_id1 = self.fc_x2_id1(x2_id1)\n",
    "        x3_new_id1 = self.fc_x3_id1(x3_id1)\n",
    "\n",
    "        x1_new_id2 = self.fc_x1_id2(x1_id2)\n",
    "        x2_new_id2 = self.fc_x2_id2(x2_id2)\n",
    "        x3_new_id2 = self.fc_x3_id2(x3_id2)\n",
    "\n",
    "        x1_new_id3 = self.fc_x1_id3(x1_id3)\n",
    "        x2_new_id3 = self.fc_x2_id3(x2_id3)\n",
    "        x3_new_id3 = self.fc_x3_id3(x3_id3)\n",
    "\n",
    "        x1_new_id4 = self.fc_x1_id4(x1_id4)\n",
    "        x2_new_id4 = self.fc_x2_id4(x2_id4)\n",
    "        x3_new_id4 = self.fc_x3_id4(x3_id4)\n",
    "\n",
    "        x1_new_id5 = self.fc_x1_id5(x1_id5)\n",
    "        x2_new_id5 = self.fc_x2_id5(x2_id5)\n",
    "        x3_new_id5 = self.fc_x3_id5(x3_id5)\n",
    "\n",
    "\n",
    "        # # Design D\n",
    "        # # 1 output train\n",
    "        # x1_1_output_id1 = self.fc_x1_0_1_id1(x1_id1)\n",
    "        # x2_1_output_id1 = self.fc_x2_0_1_id1(x2_id1)\n",
    "        # x3_1_output_id1 = self.fc_x3_0_1_id1(x3_id1)\n",
    "\n",
    "        # x1_1_output_id2 = self.fc_x1_0_1_id2(x1_id2)\n",
    "        # x2_1_output_id2 = self.fc_x2_0_1_id2(x2_id2)\n",
    "        # x3_1_output_id2 = self.fc_x3_0_1_id2(x3_id2)\n",
    "\n",
    "        # x1_1_output_id3 = self.fc_x1_0_1_id3(x1_id3)\n",
    "        # x2_1_output_id3 = self.fc_x2_0_1_id3(x2_id3)\n",
    "        # x3_1_output_id3 = self.fc_x3_0_1_id3(x3_id3)\n",
    "\n",
    "        # x1_1_output_id4 = self.fc_x1_0_1_id4(x1_id4)\n",
    "        # x2_1_output_id4 = self.fc_x2_0_1_id4(x2_id4)\n",
    "        # x3_1_output_id4 = self.fc_x3_0_1_id4(x3_id4)\n",
    "\n",
    "        # x1_1_output_id5 = self.fc_x1_0_1_id5(x1_id5)\n",
    "        # x2_1_output_id5 = self.fc_x2_0_1_id5(x2_id5)\n",
    "        # x3_1_output_id5 = self.fc_x3_0_1_id5(x3_id5)\n",
    "\n",
    "        # # 2 input cat\n",
    "        # x1_2_input_id1 = torch.cat((x1_1_output_id1, x2_1_output_id1, x2_1_output_id2, x2_1_output_id3, x2_1_output_id4, x2_1_output_id5), 1)\n",
    "        # x2_2_input_id1 = torch.cat((x1_1_output_id1, x2_1_output_id1, x2_1_output_id2, x2_1_output_id3, x2_1_output_id4, x2_1_output_id5), 1)\n",
    "        # x3_2_input_id1 = x2_1_output_id1\n",
    "\n",
    "        # x1_2_input_id2 = torch.cat((x1_1_output_id2, x2_1_output_id1, x2_1_output_id2, x2_1_output_id3, x2_1_output_id4, x2_1_output_id5), 1)\n",
    "        # x2_2_input_id2 = torch.cat((x1_1_output_id2, x2_1_output_id1, x2_1_output_id2, x2_1_output_id3, x2_1_output_id4, x2_1_output_id5), 1)\n",
    "        # x3_2_input_id2 = x2_1_output_id2\n",
    "\n",
    "        # x1_2_input_id3 = torch.cat((x1_1_output_id3, x2_1_output_id1, x2_1_output_id2, x2_1_output_id3, x2_1_output_id4, x2_1_output_id5), 1)\n",
    "        # x2_2_input_id3 = torch.cat((x1_1_output_id3, x2_1_output_id1, x2_1_output_id2, x2_1_output_id3, x2_1_output_id4, x2_1_output_id5), 1)\n",
    "        # x3_2_input_id3 = x2_1_output_id3\n",
    "\n",
    "        # x1_2_input_id4 = torch.cat((x1_1_output_id4, x2_1_output_id1, x2_1_output_id2, x2_1_output_id3, x2_1_output_id4, x2_1_output_id5), 1)\n",
    "        # x2_2_input_id4 = torch.cat((x1_1_output_id4, x2_1_output_id1, x2_1_output_id2, x2_1_output_id3, x2_1_output_id4, x2_1_output_id5), 1)\n",
    "        # x3_2_input_id4 = x2_1_output_id4\n",
    "\n",
    "        # x1_2_input_id5 = torch.cat((x1_1_output_id5, x2_1_output_id1, x2_1_output_id2, x2_1_output_id3, x2_1_output_id4, x2_1_output_id5), 1)\n",
    "        # x2_2_input_id5 = torch.cat((x1_1_output_id5, x2_1_output_id1, x2_1_output_id2, x2_1_output_id3, x2_1_output_id4, x2_1_output_id5), 1)\n",
    "        # x3_2_input_id5 = x2_1_output_id5\n",
    "\n",
    "        # # 2 output train\n",
    "        # x1_2_output_id1 = self.fc_x1_1_2_id1(x1_2_input_id1)\n",
    "        # x2_2_output_id1 = self.fc_x2_1_2_id1(x2_2_input_id1)\n",
    "        # x3_2_output_id1 = self.fc_x3_1_2_id1(x3_2_input_id1)\n",
    "\n",
    "        # x1_2_output_id2 = self.fc_x1_1_2_id2(x1_2_input_id2)\n",
    "        # x2_2_output_id2 = self.fc_x2_1_2_id2(x2_2_input_id2)\n",
    "        # x3_2_output_id2 = self.fc_x3_1_2_id2(x3_2_input_id2)\n",
    "\n",
    "        # x1_2_output_id3 = self.fc_x1_1_2_id3(x1_2_input_id3)\n",
    "        # x2_2_output_id3 = self.fc_x2_1_2_id3(x2_2_input_id3)\n",
    "        # x3_2_output_id3 = self.fc_x3_1_2_id3(x3_2_input_id3)\n",
    "\n",
    "        # x1_2_output_id4 = self.fc_x1_1_2_id4(x1_2_input_id4)\n",
    "        # x2_2_output_id4 = self.fc_x2_1_2_id4(x2_2_input_id4)\n",
    "        # x3_2_output_id4 = self.fc_x3_1_2_id4(x3_2_input_id4)\n",
    "\n",
    "        # x1_2_output_id5 = self.fc_x1_1_2_id5(x1_2_input_id5)\n",
    "        # x2_2_output_id5 = self.fc_x2_1_2_id5(x2_2_input_id5)\n",
    "        # x3_2_output_id5 = self.fc_x3_1_2_id5(x3_2_input_id5)\n",
    "\n",
    "        # # 3 input cat\n",
    "        # x1_3_input_id1 = torch.cat((x1_2_output_id1, x2_2_output_id1, x2_2_output_id2, x2_2_output_id3, x2_2_output_id4, x2_2_output_id5), 1)\n",
    "        # x2_3_input_id1 = torch.cat((x1_2_output_id1, x2_2_output_id1, x2_2_output_id2, x2_2_output_id3, x2_2_output_id4, x2_2_output_id5), 1)\n",
    "        # x3_3_input_id1 = x2_2_output_id1\n",
    "\n",
    "        # x1_3_input_id2 = torch.cat((x1_2_output_id2, x2_2_output_id1, x2_2_output_id2, x2_2_output_id3, x2_2_output_id4, x2_2_output_id5), 1)\n",
    "        # x2_3_input_id2 = torch.cat((x1_2_output_id2, x2_2_output_id1, x2_2_output_id2, x2_2_output_id3, x2_2_output_id4, x2_2_output_id5), 1)\n",
    "        # x3_3_input_id2 = x2_2_output_id2\n",
    "\n",
    "        # x1_3_input_id3 = torch.cat((x1_2_output_id3, x2_2_output_id1, x2_2_output_id2, x2_2_output_id3, x2_2_output_id4, x2_2_output_id5), 1)\n",
    "        # x2_3_input_id3 = torch.cat((x1_2_output_id3, x2_2_output_id1, x2_2_output_id2, x2_2_output_id3, x2_2_output_id4, x2_2_output_id5), 1)\n",
    "        # x3_3_input_id3 = x2_2_output_id3\n",
    "\n",
    "        # x1_3_input_id4 = torch.cat((x1_2_output_id4, x2_2_output_id1, x2_2_output_id2, x2_2_output_id3, x2_2_output_id4, x2_2_output_id5), 1)\n",
    "        # x2_3_input_id4 = torch.cat((x1_2_output_id4, x2_2_output_id1, x2_2_output_id2, x2_2_output_id3, x2_2_output_id4, x2_2_output_id5), 1)\n",
    "        # x3_3_input_id4 = x2_2_output_id4\n",
    "\n",
    "        # x1_3_input_id5 = torch.cat((x1_2_output_id5, x2_2_output_id1, x2_2_output_id2, x2_2_output_id3, x2_2_output_id4, x2_2_output_id5), 1)\n",
    "        # x2_3_input_id5 = torch.cat((x1_2_output_id5, x2_2_output_id1, x2_2_output_id2, x2_2_output_id3, x2_2_output_id4, x2_2_output_id5), 1)\n",
    "        # x3_3_input_id5 = x2_2_output_id5\n",
    "\n",
    "        # # 3 output train\n",
    "        # x1_3_output_id1 = self.fc_x1_2_3_id1(x1_3_input_id1)\n",
    "        # x2_3_output_id1 = self.fc_x2_2_3_id1(x2_3_input_id1)\n",
    "        # x3_3_output_id1 = self.fc_x3_2_3_id1(x3_3_input_id1)\n",
    "\n",
    "        # x1_3_output_id2 = self.fc_x1_2_3_id2(x1_3_input_id2)\n",
    "        # x2_3_output_id2 = self.fc_x2_2_3_id2(x2_3_input_id2)\n",
    "        # x3_3_output_id2 = self.fc_x3_2_3_id2(x3_3_input_id2)\n",
    "\n",
    "        # x1_3_output_id3 = self.fc_x1_2_3_id3(x1_3_input_id3)\n",
    "        # x2_3_output_id3 = self.fc_x2_2_3_id3(x2_3_input_id3)\n",
    "        # x3_3_output_id3 = self.fc_x3_2_3_id3(x3_3_input_id3)\n",
    "\n",
    "        # x1_3_output_id4 = self.fc_x1_2_3_id4(x1_3_input_id4)\n",
    "        # x2_3_output_id4 = self.fc_x2_2_3_id4(x2_3_input_id4)\n",
    "        # x3_3_output_id4 = self.fc_x3_2_3_id4(x3_3_input_id4)\n",
    "\n",
    "        # x1_3_output_id5 = self.fc_x1_2_3_id5(x1_3_input_id5)\n",
    "        # x2_3_output_id5 = self.fc_x2_2_3_id5(x2_3_input_id5)\n",
    "        # x3_3_output_id5 = self.fc_x3_2_3_id5(x3_3_input_id5)\n",
    "\n",
    "        # # final output\n",
    "        # x1_new_id1 = self.fc_x1_3_4_id1(x1_3_output_id1)\n",
    "        # x2_new_id1 = self.fc_x2_3_4_id1(x2_3_output_id1)\n",
    "        # x3_new_id1 = self.fc_x3_3_4_id1(x3_3_output_id1)\n",
    "\n",
    "        # x1_new_id2 = self.fc_x1_3_4_id2(x1_3_output_id2)\n",
    "        # x2_new_id2 = self.fc_x2_3_4_id2(x2_3_output_id2)\n",
    "        # x3_new_id2 = self.fc_x3_3_4_id2(x3_3_output_id2)\n",
    "\n",
    "        # x1_new_id3 = self.fc_x1_3_4_id3(x1_3_output_id3)\n",
    "        # x2_new_id3 = self.fc_x2_3_4_id3(x2_3_output_id3)\n",
    "        # x3_new_id3 = self.fc_x3_3_4_id3(x3_3_output_id3)\n",
    "\n",
    "        # x1_new_id4 = self.fc_x1_3_4_id4(x1_3_output_id4)\n",
    "        # x2_new_id4 = self.fc_x2_3_4_id4(x2_3_output_id4)\n",
    "        # x3_new_id4 = self.fc_x3_3_4_id4(x3_3_output_id4)\n",
    "\n",
    "        # x1_new_id5 = self.fc_x1_3_4_id5(x1_3_output_id5)\n",
    "        # x2_new_id5 = self.fc_x2_3_4_id5(x2_3_output_id5)\n",
    "        # x3_new_id5 = self.fc_x3_3_4_id5(x3_3_output_id5)\n",
    "\n",
    "        outputs = torch.cat((x1_new_id1, x1_new_id2, x1_new_id3, x1_new_id4, x1_new_id5, x2_new_id1, x2_new_id2, x2_new_id3, x2_new_id4, x2_new_id5, x3_new_id1, x3_new_id2, x3_new_id3, x3_new_id4, x3_new_id5), 1)\n",
    "        return outputs\n",
    "\n",
    "    def generate_x(self):\n",
    "        x = [[i*self.config.T_unit] * (self.config.n * 3) for i in range(self.config.N)]  # toy\n",
    "        x = np.asarray(x)\n",
    "        x = self.encode_t(x)\n",
    "        self.x = torch.Tensor(x).float().to(self.device)\n",
    "        self.accurate_x = [i*self.config.T_unit for i in range(self.config.N)]\n",
    "        print(\"[continuous] self.x: shape = {}\".format(self.x.shape))\n",
    "\n",
    "    def initial_start(self):\n",
    "        self.t0 = torch.Tensor(np.asarray([-1.0, -1.0, -1.0] * self.config.n).reshape([1, -1])).float().to(self.device)\n",
    "        self.y0 = torch.Tensor(np.asarray(\n",
    "            [self.config.S_start] * self.config.n + [self.config.I_start] * self.config.n + [self.config.R_start] * self.config.n\n",
    "            ).reshape([1, -1])).float().to(self.device)\n",
    "        # self.yend = torch.Tensor(np.asarray([0, 0, 100]).reshape([1, -1])).float().to(self.device)\n",
    "        # self.tend = torch.Tensor(np.asarray([1.0, 1.0, 1.0]).reshape([1, -1])).float().to(self.device)\n",
    "    \n",
    "    def loss_only_ground_truth(self):\n",
    "        self.eval()\n",
    "        y = self.forward(self.x)\n",
    "        self.y_record = y\n",
    "        # self.loss_norm = torch.nn.MSELoss().to(self.device)\n",
    "        # print(y.shape, self.gt_data.shape)\n",
    "        loss = self.loss_norm(y, self.gt_data)\n",
    "        self.train()\n",
    "        return loss, [loss]\n",
    "    \n",
    "    def real_loss(self):\n",
    "        self.eval()\n",
    "        y = self.forward(self.config.x_real)\n",
    "        real_loss = self.loss_norm(y[:self.config.N, :], self.config.gt_real_data[:self.config.N, :])\n",
    "        return real_loss\n",
    "\n",
    "\n",
    "    def loss(self, epoch=None):\n",
    "        self.eval()\n",
    "        # cp = CheckPoint()\n",
    "        y = self.forward(self.x)\n",
    "        self.y_record = y\n",
    "        # s = y[:, 0:1]\n",
    "        # i = y[:, 1:2]\n",
    "        # r = y[:, 2:3]\n",
    "        # cp.time(\"c1\")\n",
    "        s = y[:, 0: self.config.n]\n",
    "        i = y[:, self.config.n: self.config.n * 2]\n",
    "        r = y[:, self.config.n * 2: self.config.n * 3]\n",
    "\n",
    "        s_t_collection, i_t_collection, r_t_collection = [], [], []\n",
    "        for ii in range(self.config.n):\n",
    "          s_t_collection.append(torch.gradient(s[:,ii:ii+1].reshape([self.config.N]), spacing=(self.decode_t(self.x)[:, 0:1].reshape([self.config.N]),))[0].reshape([self.config.N,1]))\n",
    "          i_t_collection.append(torch.gradient(i[:,ii:ii+1].reshape([self.config.N]), spacing=(self.decode_t(self.x)[:, 0:1].reshape([self.config.N]),))[0].reshape([self.config.N,1]))\n",
    "          r_t_collection.append(torch.gradient(r[:,ii:ii+1].reshape([self.config.N]), spacing=(self.decode_t(self.x)[:, 0:1].reshape([self.config.N]),))[0].reshape([self.config.N,1]))\n",
    "        s_t = torch.cat(s_t_collection, 1)\n",
    "        i_t = torch.cat(i_t_collection, 1)\n",
    "        r_t = torch.cat(r_t_collection, 1)\n",
    "\n",
    "        # cp.time(\"c2\")\n",
    "        # s_ids, i_ids, r_ids = [], [], []\n",
    "        # for i in range(self.config.n):\n",
    "        #   s_ids.append(y[:, i:i+1])\n",
    "        #   i_ids.append(y[:, self.config.n+i: self.config.n+i+1])\n",
    "        #   r_ids.append(y[:, 2*self.config.n+i: 2*self.config.n+i+1])\n",
    "        \n",
    "        # s_t = torch.gradient(y[:, 0:1].reshape([self.config.N]), spacing=(self.decode_t(self.x)[:, 0:1].reshape([self.config.N]),))[0]\n",
    "        # i_t = torch.gradient(y[:, 1:2].reshape([self.config.N]), spacing=(self.decode_t(self.x)[:, 1:2].reshape([self.config.N]),))[0]\n",
    "        # r_t = torch.gradient(y[:, 2:3].reshape([self.config.N]), spacing=(self.decode_t(self.x)[:, 2:3].reshape([self.config.N]),))[0]\n",
    "        # s_t_ids, i_t_ids, r_t_ids = [], [], []\n",
    "        # for i in range(self.config.n):\n",
    "        #   s_t_ids.append(torch.gradient(s_ids[i].reshape([self.config.N]), spacing=(self.decode_t(self.x)[:, 0:1].reshape([self.config.N]),))[0].reshape([self.config.N, 1]))\n",
    "        #   i_t_ids.append(torch.gradient(i_ids[i].reshape([self.config.N]), spacing=(self.decode_t(self.x)[:, 0:1].reshape([self.config.N]),))[0].reshape([self.config.N, 1]))\n",
    "        #   r_t_ids.append(torch.gradient(r_ids[i].reshape([self.config.N]), spacing=(self.decode_t(self.x)[:, 0:1].reshape([self.config.N]),))[0].reshape([self.config.N, 1]))\n",
    "        \n",
    "        # s_t = s_t.reshape([self.config.N, 1])\n",
    "        # i_t = i_t.reshape([self.config.N, 1])\n",
    "        # r_t = r_t.reshape([self.config.N, 1])\n",
    "        \n",
    "        # f_s = s_t - (- self.config.beta * s * i / self.config.NN + self.config.lam - self.config.mu * s)\n",
    "        # f_i = i_t - (self.config.beta * s * i / self.config.NN - self.config.gamma * i - self.config.mu * i)\n",
    "        # f_r = r_t - (self.config.gamma * i - self.config.mu * r)\n",
    "\n",
    "        tmp_s_t_target_collection, tmp_i_t_target_collection, tmp_r_t_target_collection = [], [], []\n",
    "        for ii in range(self.config.n):\n",
    "          tmp_s_t_target = torch.zeros([self.config.N, 1]).to(self.device)\n",
    "          tmp_i_t_target = torch.zeros([self.config.N, 1]).to(self.device)\n",
    "          tmp_r_t_target = torch.zeros([self.config.N, 1]).to(self.device)\n",
    "          for jj in range(self.config.n):\n",
    "            # print(s[:, ii:ii+1].shape)\n",
    "            # print(self.config.M[i][jj])\n",
    "            tmp_s_t_target += (-self.config.beta * s[:, ii:ii+1] * self.config.M[ii][jj] * i[:, jj:jj+1]) / self.config.NN\n",
    "            tmp_i_t_target += (self.config.beta * s[:, ii:ii+1] * self.config.M[ii][jj] * i[:, jj:jj+1]) / self.config.NN\n",
    "          tmp_i_t_target -= self.config.gamma * i[:, ii:ii+1]\n",
    "          tmp_r_t_target += self.config.gamma * i[:, ii:ii+1]\n",
    "          tmp_s_t_target += (- self.config.mu * s[:, ii:ii+1] + self.config.lam)\n",
    "          tmp_i_t_target += (- self.config.mu * i[:, ii:ii+1])\n",
    "          tmp_r_t_target += (- self.config.mu * r[:, ii:ii+1])\n",
    "          tmp_s_t_target_collection.append(tmp_s_t_target)\n",
    "          tmp_i_t_target_collection.append(tmp_i_t_target)\n",
    "          tmp_r_t_target_collection.append(tmp_r_t_target)\n",
    "        s_t_target = torch.cat(tmp_s_t_target_collection, 1)\n",
    "        i_t_target = torch.cat(tmp_i_t_target_collection, 1)\n",
    "        r_t_target = torch.cat(tmp_r_t_target_collection, 1)\n",
    "\n",
    "        f_s = s_t - s_t_target\n",
    "        f_i = i_t - i_t_target\n",
    "        f_r = r_t - r_t_target\n",
    "        # cp.time(\"c3\")\n",
    "        \n",
    "        f_y = torch.cat((f_s, f_i, f_r), 1)\n",
    "        y0_pred = self.forward(self.t0)\n",
    "        \n",
    "        # i_1 = i[:, 0:1]\n",
    "        # i_2 = i[:, 1:2]\n",
    "        # i_3 = i[:, 2:3]\n",
    "        # i_4 = i[:, 3:4]\n",
    "        # i_5 = i[:, 4:5]\n",
    "\n",
    "        # r_1 = r[:, 0:1]\n",
    "        # r_2 = r[:, 1:2]\n",
    "        # r_3 = r[:, 2:3]\n",
    "        # r_4 = r[:, 3:4]\n",
    "        # r_5 = r[:, 4:5]\n",
    "\n",
    "        # loss_1 = torch.mean(torch.square(self.y0 - y0_pred))\n",
    "        # self.loss_norm = torch.nn.MSELoss().to(self.device)\n",
    "        # self.loss_norm = RMSELoss # nn.MSELoss().to(self.device) #RMSELoss().to(self.device)\n",
    "\n",
    "        # zeros_1D = torch.Tensor([[0.0]] * self.config.N).to(self.device)\n",
    "        # zeros_2D = torch.Tensor([[0.0, 0.0]] * self.config.N).to(self.device)\n",
    "        # zeros_3D = torch.Tensor([[0.0, 0.0, 0.0]] * self.config.N).to(self.device)\n",
    "        zeros_15D = torch.Tensor([[0.0] * 15] * self.config.N).to(self.device)\n",
    "        # print(\"y[:self.config.truth_length, :]\", y[:self.config.truth_length, :].shape, y[:self.config.truth_length, :])\n",
    "        # print(\"self.gt_data[:self.config.truth_length, :]\", self.gt_data[:self.config.truth_length, :].shape, self.gt_data[:self.config.truth_length, :])\n",
    "        # print(\"zeros_15D\", zeros_15D.shape, zeros_15D)\n",
    "        # print(\"f_y\", f_y.shape, f_y)\n",
    "        # print(\"torch.abs(y) - y\", (torch.abs(y) - y).shape, torch.abs(y) - y)\n",
    "        loss_1 = self.loss_norm(y[:self.config.truth_length, :], self.gt_data[:self.config.truth_length, :])\n",
    "        # cp.time(\"c4\")\n",
    "        if self.config.sliding_window_flag:\n",
    "            if self.config.sw_normal_flag:\n",
    "                self.loss_2_weight_numpy = generate_normal_distribution_weight(self.config.N, self.config.n * 3, (epoch % int(self.config.normal_sliding_window_step)) / self.config.normal_sliding_window_step)\n",
    "                loss_2 = self.loss_norm(f_y * torch.Tensor(self.loss_2_weight_numpy).to(self.device), zeros_15D)\n",
    "            else:\n",
    "                self.loss_2_weight_numpy = generate_brick_distribution_weight(self.config.N, self.config.n * 3, epoch / self.config.epoch_max)\n",
    "                loss_2 = self.loss_norm(f_y * torch.Tensor(self.loss_2_weight_numpy).to(self.device), zeros_15D)\n",
    "\n",
    "        else:\n",
    "            loss_2 = self.loss_norm(f_y, zeros_15D) #torch.mean(torch.square(f_y))  # + torch.var(torch.square(f_y))\n",
    "\n",
    "        loss_3 = self.loss_norm(torch.abs(y), y) # torch.mean(torch.square((torch.abs(s) - s))) + torch.mean(torch.square((torch.abs(i) - i))) + torch.mean(torch.square((torch.abs(r) - r))) #+ torch.mean(torch.square((0.1/(s * s)))) + torch.mean(torch.square((0.1/(i * i)))) + torch.mean(torch.square((0.1/(r * r))))\n",
    "        # loss_4 = torch.mean(torch.square(0.00001 / ((s * s + i * i) * (i * i + r * r) * (s * s + r * r) + 1e-8)))\n",
    "        loss_4 = self.match_truth(self.accurate_x, y.cpu().detach().numpy())\n",
    "        # cp.time(\"c5\")\n",
    "        # 04/27 TODO: re-design the loss functions. I want to do it but Chen asked me to implement new models. Now it's your turn.\n",
    "\n",
    "        loss = loss_1 + loss_2 + loss_3 + loss_4\n",
    "        # if loss < 2.0:\n",
    "        #     f_y_square_pure = torch.square(f_y).cpu().detach().numpy()\n",
    "        #     for i in range(20000):\n",
    "        #         print(i, f_y_square_pure[i])\n",
    "        self.train()\n",
    "        # cp.time(\"c6\")\n",
    "        return loss, [loss_1, loss_2, loss_3, loss_4]\n",
    "        # return torch.mean(torch.square(y_hat - y))\n",
    "        # return F.mse_loss(torch.cat((u_hat, v_hat), 1), torch.cat((u, v), 1))\n",
    "        # return torch.abs(u_hat - u) + torch.abs(v_hat - v)  # F.mse_loss(x_hat, x) + beta * self.kl_div(rho)\n",
    "    \n",
    "    def match_truth(self, x, y):\n",
    "        # print(type(x), type(y))\n",
    "        if len(self.truth[0]) == 0:\n",
    "            return torch.Tensor([0.0]).to(self.device)\n",
    "        diff = [np.abs(y_tmp - self.truth_dic.get(round(x_tmp, self.config.round_bit))) for x_tmp, y_tmp in zip(x, y) if round(x_tmp, self.config.round_bit) in self.truth_dic]\n",
    "        diff = torch.Tensor(diff).to(self.device)\n",
    "        zeros_2D = torch.Tensor([[0.0] * self.config.n * 3] * len(diff)).to(self.device)\n",
    "        loss_truth_match = self.loss_norm(diff, zeros_2D)\n",
    "        if len(diff) != len(self.truth[0]):\n",
    "            print(\"Error: match_truth: {} / {} items to match, loss_truth_match = {}\".format(len(diff), len(self.truth[0]), loss_truth_match.item()))\n",
    "        return loss_truth_match\n",
    "\n",
    "    def encode_t(self, num):\n",
    "        if not self.config.mapping_overall_flag:\n",
    "            return (num - self.config.lb) / (self.config.ub - self.config.lb) * 2.0 - 1.0\n",
    "        return num / self.config.T_all * 2.0 - 1.0\n",
    "\n",
    "    def decode_t(self, num):\n",
    "        if not self.config.mapping_overall_flag:\n",
    "            return self.config.lb + (num + 1.0) / 2.0 * (self.config.ub - self.config.lb)\n",
    "        return (num + 1.0) / 2.0 * self.config.T_all\n",
    "\n",
    "    @staticmethod\n",
    "    def setup_seed(seed):\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2187,
     "status": "ok",
     "timestamp": 1657242781632,
     "user": {
      "displayName": "Group Chen",
      "userId": "07021887056990447026"
     },
     "user_tz": 240
    },
    "id": "Y6HU0RmnCWm5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GroundTruthSIRAges:\n",
    "  def __init__(self, t_max, length):\n",
    "    S_start = 50.0  # 99.0\n",
    "    I_start = 40.0 # 1.0\n",
    "    R_start = 10#1.0 # 0.0\n",
    "    NN = S_start + I_start + R_start\n",
    "    beta = 0.01\n",
    "    gamma = 0.05\n",
    "    mu = 0.03\n",
    "    lam = mu * NN\n",
    "    \n",
    "    # print(t)\n",
    "    M = np.asarray([\n",
    "          [19.200, 4.800, 5.050, 3.400, 1.700],\n",
    "          [4.800, 42.400, 5.900, 6.250, 1.733],\n",
    "          [5.050, 5.900, 14.000, 7.575, 1.700],\n",
    "          [3.400, 6.250, 7.575, 9.575, 1.544],\n",
    "          [1.700, 1.733, 1.700, 1.544, 5.456],\n",
    "        ])\n",
    "    self.n = len(M)\n",
    "    y0 = np.asarray([S_start] * self.n + [I_start] * self.n + [R_start] * self.n)\n",
    "    self.t = np.linspace(0, t_max, length)\n",
    "    self.data = odeint(self.pend, y0, self.t, args=(M, beta, gamma, NN, self.n, mu, lam))\n",
    "  \n",
    "  @staticmethod\n",
    "  def pend(y, t, M, beta, gamma, NN, n, mu, lam):\n",
    "    map = y\n",
    "    #dydt = np.asarray([(a * map[0]) - c * map[0] * map[1], - b * map[1] + d * c * map[0] * map[1]])\n",
    "    S_arr = y[0: n]\n",
    "    I_arr = y[n: 2 * n]\n",
    "    R_arr = y[2 * n: 3 * n]\n",
    "    ds = []\n",
    "    di = []\n",
    "    dr = []\n",
    "    for i in range(n):\n",
    "      ds.append(- beta * S_arr[i] / NN * sum([M[i][j] * I_arr[j] for j in range(n)]) - mu * S_arr[i] + lam)\n",
    "      di.append(beta * S_arr[i] / NN * sum([M[i][j] * I_arr[j] for j in range(n)]) - gamma * I_arr[i] - mu * I_arr[i])\n",
    "      dr.append(gamma * I_arr[i] - mu * R_arr[i])\n",
    "    dydt = np.asarray(ds + di + dr)\n",
    "    return dydt\n",
    "  \n",
    "  def print(self):\n",
    "    y_lists = [self.data[:, i] for i in range(3 * self.n)]\n",
    "    x_list = self.t\n",
    "    color_list = [\"red\"] * self.n + [\"blue\"] * self.n + [\"green\"] * self.n\n",
    "    labels = [\"0-9\", \"10-19\", \"20-39\", \"40-59\", \"60+\"]\n",
    "    legend_list = [\"S{}({})\".format(i + 1, labels[i]) for i in range(self.n)] + [\"I{}({})\".format(i + 1, labels[i]) for i in range(self.n)] + [\"R{}({})\".format(i + 1, labels[i]) for i in range(self.n)]\n",
    "    line_style_list = [\"dashed\", \"dotted\", \"dashdot\", (0, (3, 1, 1, 1, 1, 1)), (0, (3, 10, 1, 10))] * 3\n",
    "\n",
    "    draw_two_dimension(\n",
    "        y_lists=y_lists,\n",
    "        x_list=x_list,\n",
    "        color_list=color_list,\n",
    "        legend_list=legend_list,\n",
    "        line_style_list=line_style_list,\n",
    "        fig_title=\"Ground Truth: SIR - Ages\",\n",
    "        fig_size=(8, 6),\n",
    "        show_flag=True,\n",
    "        save_flag=False,\n",
    "        save_path=None\n",
    "    )\n",
    "class CheckPoint:\n",
    "  def __init__(self):\n",
    "    self.id = 0\n",
    "    self.t = time.time()\n",
    "\n",
    "  def full_time(self):\n",
    "    # return time.strftime(\"%Y-%m-%d-%H-%M-%S.%fZ\", time.localtime(time.time()))\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "  \n",
    "  def time(self, label=None):\n",
    "    self.id += 1\n",
    "    t_new = time.time()\n",
    "    print(\"[{0}] Check Point {1:02d}: {2:.12f}s{3}\".format(self.full_time(), self.id, t_new - self.t, \" ({})\".format(label) if label else \"\"))\n",
    "    self.t = t_new\n",
    "\n",
    "\n",
    "def get_now_string():\n",
    "    return time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(time.time()))\n",
    "\n",
    "def generate_normal_distribution_weight(length, width, mu_location):\n",
    "    mu = mu_location * length\n",
    "    sigma = length // 10\n",
    "    x = np.linspace(0, length, length)\n",
    "    y = 1e2 * length * stats.norm.pdf(x, mu, sigma)\n",
    "    y = y / y.sum() * length\n",
    "    # print(y)\n",
    "    # plt.plot(x, y)\n",
    "    # print(x[:5], x[-5:])\n",
    "    # print(y.shape)\n",
    "    # print(y)\n",
    "    # plt.show()\n",
    "    res = np.column_stack([y for i in range(width)])\n",
    "    # print(res.shape)\n",
    "    return res\n",
    "\n",
    "def generate_brick_distribution_weight(length, width, epoch_ratio, epoch_freeze=0.15, epoch_moving=0.05, epoch_final=0.40):\n",
    "    # epoch_ratio = epoch / epoch_max\n",
    "    if epoch_ratio <= epoch_freeze:\n",
    "      weight_range = [0, 0.25 * length]\n",
    "    elif epoch_freeze < epoch_ratio <= epoch_freeze + epoch_moving:\n",
    "      weight_range = [0, (0.25 + (epoch_ratio - (1 * epoch_freeze)) / epoch_moving * 0.25) * length]\n",
    "    elif epoch_freeze + epoch_moving < epoch_ratio <= 2 * epoch_freeze + epoch_moving:\n",
    "      weight_range = [0, 0.5 * length]\n",
    "    elif 2 * epoch_freeze + epoch_moving < epoch_ratio <= 2 * epoch_freeze + 2 * epoch_moving:\n",
    "      weight_range = [0, (0.5 + (epoch_ratio - (2 * epoch_freeze + epoch_moving)) / epoch_moving * 0.25) * length]\n",
    "    elif 2 * epoch_freeze + 2 * epoch_moving < epoch_ratio <= 3 * epoch_freeze + 2 * epoch_moving:\n",
    "      weight_range = [0, 0.75 * length]\n",
    "    elif 3 * epoch_freeze + 2 * epoch_moving < epoch_ratio <= 3 * epoch_freeze + 3 * epoch_moving:\n",
    "      weight_range = [0, (0.75 + (epoch_ratio - (3 * epoch_freeze + 2 * epoch_moving)) / epoch_moving * 0.25) * length]\n",
    "    elif 3 * epoch_freeze + 3 * epoch_moving < epoch_ratio <= 1.0:\n",
    "      weight_range = [0, 1.0 * length]\n",
    "\n",
    "    weight_high = length * 1 / (weight_range[1] - weight_range[0])\n",
    "    y = [weight_high if i < weight_range[1] else 0 for i in range(length)]\n",
    "    y = np.asarray(y)\n",
    "    y = y / y.sum() * length\n",
    "    res = np.column_stack([y for i in range(width)])\n",
    "    return res\n",
    "\n",
    "\n",
    "def train_sir_ages(model, args, config, now_string, resume_epoch=None, resume_loss_record=None, resume_real_loss_record=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # model = model_framework(config).to(device)\n",
    "    model.train()\n",
    "    model_save_path_last = f\"{args.main_path}/train/{model.model_name}_{args.epoch}_{args.epoch_step}_{args.lr}_{config.beta}_{config.gamma}_{now_string}_last.pt\"\n",
    "    model_save_path_best = f\"{args.main_path}/train/{model.model_name}_{args.epoch}_{args.epoch_step}_{args.lr}_{config.beta}_{config.gamma}_{now_string}_best.pt\"\n",
    "    loss_save_path = f\"{args.main_path}/loss/{model.model_name}_{args.epoch}_{args.epoch_step}_{args.lr}_{now_string}_loss_{args.epoch}.npy\"\n",
    "    real_loss_save_path = f\"{args.main_path}/loss/{model.model_name}_{args.epoch}_{args.epoch_step}_{args.lr}_{now_string}_real_loss_{args.epoch}.npy\"\n",
    "    y_record_save_path = f\"{args.main_path}/loss/{model.model_name}_{args.epoch}_{args.epoch_step}_{args.lr}_{now_string}_y_record.npy\"\n",
    "    print(\"using \" + str(device))\n",
    "    print(\"epoch = {}\".format(args.epoch))\n",
    "    print(\"epoch_step = {}\".format(args.epoch_step))\n",
    "    print(\"model_name = {}\".format(model.model_name))\n",
    "    print(\"now_string = {}\".format(now_string))\n",
    "    print(\"model_save_path_last = {}\".format(model_save_path_last))\n",
    "    print(\"model_save_path_best = {}\".format(model_save_path_best))\n",
    "    print(\"loss_save_path = {}\".format(loss_save_path))\n",
    "    print(\"real_loss_save_path = {}\".format(real_loss_save_path))\n",
    "    print(\"y_record_save_path = {}\".format(y_record_save_path))\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    initial_lr = args.lr\n",
    "    optimizer = optim.Adam(model.parameters(), lr = initial_lr)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(epoch/10000+1))\n",
    "    # scheduler = CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, step_size=1000)\n",
    "    # optimizer = optim.LBFGS(model.parameters(), lr=args.lr, max_iter=5000, max_eval=None, tolerance_grad=1e-05, tolerance_change=1e-09, history_size=100,\n",
    "    #       line_search_fn=None)\n",
    "    epoch_step = args.epoch_step\n",
    "    start_time = time.time()\n",
    "    start_time_0 = start_time\n",
    "    best_loss = np.inf\n",
    "    loss_record = []\n",
    "    real_loss_record = []\n",
    "    start_index = 1\n",
    "    if resume_epoch:\n",
    "        for i in range(resume_epoch):\n",
    "            scheduler.step()\n",
    "        loss_record = resume_loss_record\n",
    "        real_loss_record = resume_real_loss_record\n",
    "        start_index = resume_epoch + 1\n",
    "        print(\"[Resume] loss_record length:\", len(loss_record))\n",
    "        print(\"[Resume] real_loss_record length:\", len(real_loss_record))\n",
    "        print(\"[Resume] start_index:\", start_index)\n",
    "    # y_record = []\n",
    "    for epoch in range(start_index, args.epoch + 1):\n",
    "        # cp = CheckPoint()\n",
    "        optimizer.zero_grad()\n",
    "        # cp.time(\"a\")\n",
    "        inputs = model.x\n",
    "        outputs = model(inputs)\n",
    "        # cp.time(\"b\")\n",
    "        # u_hat, v_hat = torch.chunk(outputs, 2, 1)\n",
    "        if config.only_truth_flag:\n",
    "          loss, loss_list = model.loss_only_ground_truth()\n",
    "        else:\n",
    "          loss, loss_list = model.loss(epoch)\n",
    "        # cp.time(\"c\")\n",
    "        real_loss = model.real_loss()\n",
    "        # cp.time(\"d\")\n",
    "        loss.backward()\n",
    "        # cp.time(\"e\")\n",
    "        optimizer.step()\n",
    "        # cp.time(\"f\")\n",
    "        scheduler.step()\n",
    "        # cp.time(\"g\")\n",
    "        loss_record.append(float(loss.item()))\n",
    "        real_loss_record.append(float(real_loss.item()))\n",
    "        # y_record.append(model.y_record.cpu().detach().numpy())\n",
    "        # cp.time(\"h\")\n",
    "        if epoch % epoch_step == 0:\n",
    "            now_time = time.time()\n",
    "            loss_print_part = \" \".join([\"Loss_{0:d}:{1:.6f}\".format(i + 1, loss_part.item()) for i, loss_part in enumerate(loss_list)])\n",
    "            # print(\"Epoch [{0:05d}/{1:05d}] Loss:{2:.6f} Loss_1:{3:.6f} Loss_2:{4:.6f} Loss_3: {5:.6f} Lr:{6:.6f} Time:{7:.6f}s ({8:.2f}min in total)\".format(epoch, args.epoch, loss.item(), loss_1.item(), loss_2.item(), loss_3.item(), optimizer.param_groups[0][\"lr\"], now_time - start_time, (now_time - start_time_0) / 60.0))\n",
    "            print(\"Epoch [{0:05d}/{1:05d}] Loss:{2:.6f} {3} Lr:{4:.6f} Time:{5:.6f}s ({6:.2f}min in total, {7:.2f}min remains)\".format(epoch, args.epoch, loss.item(), loss_print_part, optimizer.param_groups[0][\"lr\"], now_time - start_time, (now_time - start_time_0) / 60.0, (now_time - start_time_0) / 60.0 / (epoch - start_index + 1) * (args.epoch - epoch)))\n",
    "            start_time = time.time()\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': args.epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    # 'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss.item()\n",
    "                }, model_save_path_last)\n",
    "            # print(inputs.shape)\n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                torch.save(\n",
    "                    {\n",
    "                        'epoch': args.epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        # 'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': loss.item()\n",
    "                    }, model_save_path_best)\n",
    "        if epoch % args.save_step == 0 or epoch == args.epoch:\n",
    "            test_sir_ages(model, args, config, now_string, True, model.gt)\n",
    "            print(\"[Loss]\")\n",
    "            draw_loss(np.asarray(loss_record))\n",
    "            print(\"[Real Loss]\")\n",
    "            draw_loss(np.asarray(real_loss_record))\n",
    "            np.save(loss_save_path, np.asarray(loss_record))\n",
    "            np.save(real_loss_save_path, np.asarray(real_loss_record))\n",
    "            # np.save(y_record_save_path, np.asarray(y_record))\n",
    "    loss_record = np.asarray(loss_record)\n",
    "    real_loss_record = np.asarray(real_loss_record)\n",
    "    res_dic = {\n",
    "        \"start_time\": start_time_0,\n",
    "        \"epoch\": args.epoch,\n",
    "        \"model_save_path_last\": model_save_path_last,\n",
    "        \"model_save_path_best\": model_save_path_best,\n",
    "        \"loss_save_path\": loss_save_path,\n",
    "        \"real_loss_save_path\": real_loss_save_path,\n",
    "        \"best_loss\": best_loss,\n",
    "        \"loss_record\": loss_record,\n",
    "        \"real_loss_record\": real_loss_record\n",
    "    }\n",
    "    return model, res_dic\n",
    "\n",
    "def test_sir_ages(model, args, config, now_string, show_flag=True, gt=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # model = model_framework(config).to(device)\n",
    "    # model_save_path = f\"{args.main_path}/train/{model.model_name}_{args.epoch}_{args.epoch_step}_{args.lr}_{config.beta}_{config.gamma}_{now_string}_last.pt\"\n",
    "    # model.load_state_dict(torch.load(model_save_path, map_location=device)[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    print(\"Testing & drawing...\")\n",
    "    t = model.x\n",
    "    y = model(t)\n",
    "    y0_pred = model(model.t0)\n",
    "    s, i, r = y[:, 0:5], y[:, 5:10], y[:, 10:15]\n",
    "    s = s.cpu().detach().numpy()\n",
    "    i = i.cpu().detach().numpy()\n",
    "    r = r.cpu().detach().numpy()\n",
    "    x = model.decode_t(t).cpu().detach().numpy()\n",
    "    s_pred = [s[:, id:id+1].reshape([model.config.N]) for id in range(model.config.n)]\n",
    "    i_pred = [i[:, id:id+1].reshape([model.config.N]) for id in range(model.config.n)]\n",
    "    r_pred = [r[:, id:id+1].reshape([model.config.N]) for id in range(model.config.n)]\n",
    "    x = x[:, 0:1].reshape([model.config.N])\n",
    "    for id in range(model.config.n):\n",
    "      print(f\"s{id+1}=\", list(s_pred[id][:10]), \"...\", list(s_pred[id][-10:]))\n",
    "    for id in range(model.config.n):\n",
    "      print(f\"i{id+1}=\", list(i_pred[id][:10]), \"...\", list(i_pred[id][-10:]))\n",
    "    for id in range(model.config.n):\n",
    "      print(f\"r{id+1}=\", list(r_pred[id][:10]), \"...\", list(r_pred[id][-10:]))\n",
    "\n",
    "    figure_save_path = f\"{args.main_path}/figure/{model.model_name}_{args.epoch}_{args.epoch_step}_{args.lr}_{config.beta}_{config.gamma}_{now_string}_{int(time.time())}.png\"\n",
    "    labels = [\"0-9\", \"10-19\", \"20-39\", \"40-59\", \"60+\"]\n",
    "    color_list = [\"grey\"] * (3 * model.config.n) + [\"red\"] * model.config.n + [\"blue\"] * model.config.n + [\"green\"] * model.config.n\n",
    "    legend_list = [\"S{}({})_truth\".format(i + 1, labels[i]) for i in range(model.config.n)] + [\"I{}({})_truth\".format(i + 1, labels[i]) for i in range(model.config.n)] + [\"R{}({})_truth\".format(i + 1, labels[i]) for i in range(model.config.n)] + \\\n",
    "                  [\"S{}({})\".format(i + 1, labels[i]) for i in range(model.config.n)] + [\"I{}({})\".format(i + 1, labels[i]) for i in range(model.config.n)] + [\"R{}({})\".format(i + 1, labels[i]) for i in range(model.config.n)]\n",
    "    line_style_list = [\"dashed\"] * (3 * model.config.n) + [\"dashed\", \"dotted\", \"dashdot\", (0, (3, 1, 1, 1, 1, 1)), (0, (3, 10, 1, 10))] * 3\n",
    "    y_truth = [gt.data[:, id:id+1].reshape([model.config.N]) for id in range(model.config.n * 3)]\n",
    "    if not model.config.sliding_window_flag:\n",
    "      draw_two_dimension(\n",
    "          y_lists= y_truth + s_pred + i_pred + r_pred,\n",
    "          x_list=x,\n",
    "          color_list=color_list,\n",
    "          legend_list=legend_list,\n",
    "          line_style_list=line_style_list,\n",
    "          fig_title=\"Predict: SIR - Ages\",\n",
    "          fig_size=(24, 18),\n",
    "          show_flag=True,\n",
    "          save_flag=True,\n",
    "          save_path=figure_save_path\n",
    "      )\n",
    "    else:\n",
    "      sw_weight = [item[0] for item in model.loss_2_weight_numpy]\n",
    "      draw_two_dimension(\n",
    "          y_lists= [sw_weight] + y_truth + s_pred + i_pred + r_pred,\n",
    "          x_list=x,\n",
    "          color_list=[\"black\"] + color_list,\n",
    "          legend_list=[\"sliding window weights\"] + legend_list,\n",
    "          line_style_list=[\"dotted\"] + line_style_list,\n",
    "          fig_title=\"Predict: SIR - Ages\",\n",
    "          fig_size=(24, 18),\n",
    "          show_flag=True,\n",
    "          save_flag=True,\n",
    "          save_path=figure_save_path\n",
    "      )\n",
    "\n",
    "    # pairs = [[ss, ii, rr, xx] for ss, ii, rr, xx in zip(s, i, r, x)]\n",
    "    # pairs.sort(key=lambda xx: xx[-1])\n",
    "    # s = [item[0] for item in pairs]\n",
    "    # i = [item[1] for item in pairs]\n",
    "    # r = [item[2] for item in pairs]\n",
    "    # x = [item[3] for item in pairs]\n",
    "    # print(\"s=\", s[:10], \"...\", s[-10:])\n",
    "    # print(\"i=\", i[:10], \"...\", i[-10:])\n",
    "    # print(\"r=\", r[:10], \"...\", r[-10:])\n",
    "    # print(\"x=\", x[:10], \"...\", x[-10:])\n",
    "    # plt.plot(x, s, marker='.', markersize=0.2, linewidth=0.1, c=\"b\")\n",
    "    # plt.plot(x, i, marker='.', markersize=0.2, linewidth=0.1, c=\"r\")\n",
    "    # plt.plot(x, r, marker='.', markersize=0.2, linewidth=0.1, c=\"g\")\n",
    "    # figure_save_path = f\"{args.main_path}/figure/{model.model_name}_{args.epoch}_{args.epoch_step}_{args.lr}_{config.beta}_{config.gamma}_{now_string}_{int(time.time())}.png\"\n",
    "    # plt.savefig(figure_save_path, dpi=300)\n",
    "    # if show_flag:\n",
    "    #     plt.show()\n",
    "    # plt.clf()\n",
    "    # print(\"Saved as {}\".format(figure_save_path))\n",
    "\n",
    "class Args:\n",
    "  def __init__(self):\n",
    "    self.epoch = 2000000#500000 # 500\n",
    "    self.epoch_step = 5000 # 1\n",
    "    self.lr = 0.01\n",
    "    self.main_path = \".\"\n",
    "    self.save_step = 50000#10000\n",
    "\n",
    "def draw_loss(loss_list):\n",
    "    draw_two_dimension(\n",
    "        y_lists=[loss_list],\n",
    "        x_list=range(1, len(loss_list) + 1),\n",
    "        color_list=[\"blue\"],\n",
    "        legend_list=[\"loss\"],\n",
    "        line_style_list=[\"solid\"],\n",
    "        fig_title=\"Loss - {} epochs\".format(len(loss_list)),\n",
    "        fig_x_label=\"epoch\",\n",
    "        fig_y_label=\"loss\",\n",
    "        fig_size=(8, 6),\n",
    "        show_flag=True,\n",
    "        save_flag=False,\n",
    "        save_path=None\n",
    "    )\n",
    "\n",
    "def run_sir_ages(main_path=None):\n",
    "    args = Args()\n",
    "    if main_path:\n",
    "        args.main_path = main_path\n",
    "    if not os.path.exists(\"{}/train\".format(args.main_path)):\n",
    "        os.makedirs(\"{}/train\".format(args.main_path))\n",
    "    if not os.path.exists(\"{}/figure\".format(args.main_path)):\n",
    "        os.makedirs(\"{}/figure\".format(args.main_path))\n",
    "    now_string = get_now_string()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    config = ConfigSIRAges()\n",
    "    model = SimpleNetworkSIRAges(config).to(device)\n",
    "    model, res_dic = train_sir_ages(model, args, config, now_string)\n",
    "    return res_dic\n",
    "    # model = SimpleNetworkSIRAges(config).to(device)\n",
    "    # test_sir_ages(model, args, config, now_string)\n",
    "\n",
    "\n",
    "def run_sir_ages_sliding_window(main_path=None, sw_type=\"normal\"):\n",
    "    args = Args()\n",
    "    if main_path:\n",
    "        args.main_path = main_path\n",
    "    if not os.path.exists(\"{}/train\".format(args.main_path)):\n",
    "        os.makedirs(\"{}/train\".format(args.main_path))\n",
    "    if not os.path.exists(\"{}/figure\".format(args.main_path)):\n",
    "        os.makedirs(\"{}/figure\".format(args.main_path))\n",
    "    now_string = get_now_string()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    config = ConfigSIRAges()\n",
    "    config.sliding_window_flag = True\n",
    "    config.epoch_max = args.epoch\n",
    "    if sw_type == \"normal\":\n",
    "        config.sw_normal_flag = True\n",
    "    elif sw_type == \"brick\":\n",
    "        config.sw_brick_flag = True\n",
    "    model = SimpleNetworkSIRAges(config).to(device)\n",
    "    model, res_dic = train_sir_ages(model, args, config, now_string)\n",
    "    return res_dic\n",
    "    # model = SimpleNetworkSIRAges(config).to(device)\n",
    "    # test_sir_ages(model, args, config, now_string)\n",
    "\n",
    "\n",
    "def run_sir_ages_continue(main_path=None):\n",
    "    args_0 = Args()\n",
    "    if main_path:\n",
    "        args_0.main_path = main_path\n",
    "    if not os.path.exists(\"{}/train\".format(args_0.main_path)):\n",
    "        os.makedirs(\"{}/train\".format(args_0.main_path))\n",
    "    if not os.path.exists(\"{}/figure\".format(args_0.main_path)):\n",
    "        os.makedirs(\"{}/figure\".format(args_0.main_path))\n",
    "    if not os.path.exists(\"{}/loss\".format(args_0.main_path)):\n",
    "        os.makedirs(\"{}/loss\".format(args_0.main_path))\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    now_string_list = []\n",
    "    config_0 = ConfigSIRAges()\n",
    "    continue_n = int(1.0 / config_0.continue_period)\n",
    "    truth_x = []\n",
    "    truth_y = []\n",
    "\n",
    "    real_loss_record_list = []\n",
    "    for i in range(continue_n):\n",
    "        \n",
    "        config = ConfigSIRAges()\n",
    "        config.T = config_0.T * config_0.continue_period * (i + 1)\n",
    "        config.N = int(config.T / config.T_unit)\n",
    "        config.ub = config.T\n",
    "        config.continue_id = i\n",
    "        args = copy.deepcopy(args_0)\n",
    "        args.epoch = int(args.epoch * config_0.continue_period)\n",
    "        \n",
    "        now_string = get_now_string()\n",
    "        \n",
    "        print(\"i = {}, length of truth = {} now\".format(i, len(truth_x)))\n",
    "        print(\"truth_x:\", truth_x[:2], \"...\", truth_x[-2:])\n",
    "        print(\"truth_y:\", truth_y[:2], \"...\", truth_y[-2:])\n",
    "        \n",
    "        model = SimpleNetworkSIRAges(config, [truth_x, truth_y]).to(device)\n",
    "        if i > 0:\n",
    "            model_state_dict_path =  f\"{args.main_path}/train/{config.model_name}_{args.epoch}_{args.epoch_step}_{args.lr}_{config.beta}_{config.gamma}_{now_string_list[-1]}_best.pt\"\n",
    "            model.load_state_dict(torch.load(model_state_dict_path, map_location=device)[\"model_state_dict\"])\n",
    "            print(\"Loaded previous trained model from {} successfully!\".format(model_state_dict_path))\n",
    "            print(\"Test before training...\")\n",
    "            print(\"Now string list:\", now_string_list)\n",
    "            test_sir_ages(model, args, config, now_string_list[-1], True, model.gt)\n",
    "        now_string_list.append(now_string)\n",
    "        model, res_dic = train_sir_ages(model, args, config, now_string)\n",
    "        with open(f\"{args.main_path}/train/{config.model_name}_{now_string}_i={i}.model\", \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        real_loss_record_list.append(res_dic[\"real_loss_record\"])\n",
    "        draw_loss(np.concatenate(real_loss_record_list))\n",
    "        np.save(f\"{args.main_path}/train/{config.model_name}_{now_string}_real_loss_record_i={i}.pt\", np.concatenate(real_loss_record_list))\n",
    "        y = model(model.x)\n",
    "        y = y.cpu().detach().numpy()\n",
    "        # print(\"model.accurate_x:\", model.accurate_x)\n",
    "        # print(\"y:\", y)\n",
    "        for one_x, one_y in zip(model.accurate_x, y):\n",
    "            one_x = round(one_x, model.config.round_bit)\n",
    "            if not one_x in truth_x:\n",
    "                truth_x.append(one_x)\n",
    "                truth_y.append(one_y)\n",
    "    real_loss_record_all = np.concatenate(real_loss_record_list)\n",
    "    draw_loss(real_loss_record_all)\n",
    "    real_loss_all_path = f\"{args_0.main_path}/train/{config_0.model_name}_{now_string}_real_loss_all.npy\"\n",
    "    np.save(real_loss_all_path, real_loss_record_all)\n",
    "    print(\"real_loss_all is saved to {} (length={})\".format(real_loss_all_path, len(real_loss_record_all)))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "PINN_SimpleNetworkSIRAges_C&SW.ipynb",
   "provenance": [],
   "background_execution": "on"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}